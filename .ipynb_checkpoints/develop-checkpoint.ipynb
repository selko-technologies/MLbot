{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_block(log_name, cell):\n",
    "    \"\"\"Returns True for non-empty notebook code block that contains #log_name\"\"\"\n",
    "    if cell['cell_type'] != 'code': return False\n",
    "    src = cell['source']\n",
    "    if len(src) == 0 or len(src[0]) < len(log_name)+1: return False\n",
    "    # there could be: any number of whitespace char in between # and log_name, \n",
    "    # log_name can be followed with any character, eg. s\n",
    "    return re.match(fr'^\\s*#\\s*{log_name}.*\\s*$', src[0], re.IGNORECASE) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_fpath = 'imdb_sample/example.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = json.load(open(current_fpath,'r',encoding=\"utf-8\"))\n",
    "hyperparameters = [c for c in notebook['cells'] if is_block('hyperparameter', c)]\n",
    "inputs = [c for c in notebook['cells'] if is_block('input', c)]\n",
    "outputs = [c for c in notebook['cells'] if is_block('output', c)]\n",
    "specified_metrics = [c for c in notebook['cells'] if is_block('metric', c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "idxs.append(0)\n",
    "start = ['import mlflow/n',\n",
    "         \"TRACKING_URI = 'http://admin:DnWHZxxrw7heJhoRDqNkLNTN@ec2-54-171-239-244.eu-west-1.compute.amazonaws.com'/n\",       \n",
    "         \"mlflow.set_tracking_uri(TRACKING_URI)/n\"]\n",
    "start_block = {'cell_type': 'code', \n",
    "               'execution_count': 0, \n",
    "               'metadata': {}, \n",
    "               'outputs': [], \n",
    "               'source':start}\n",
    "notebook['cells'].insert(0, start_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in hyperparameters:\n",
    "    idx = notebook['cells'].index(block) +1\n",
    "    idxs.append(idx)\n",
    "    log = []\n",
    "    for line in block['source']:\n",
    "        if re.search(r'\\=',line) is not None:\n",
    "            line = line.replace('\\n','').replace(' ','')\n",
    "            key = line.split('=')[0]\n",
    "            value = line.split('=')[-1]\n",
    "            log.append(f'mlflow.log_param({key}, {value})'+'\\n')\n",
    "    log_block = {'cell_type': 'code', \n",
    "                   'execution_count': 0, \n",
    "                   'metadata': {}, \n",
    "                   'outputs': [], \n",
    "                   'source':log}\n",
    "\n",
    "    notebook['cells'].insert(idx, log_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "texts.csv\n",
      "data_lm_export.pkl\n",
      "data_clas_export.pkl\n",
      "ft_encoder\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# get all the valid file paths from input and output blocks, log as artifacts\n",
    "for block in inputs+outputs:\n",
    "    idx = notebook['cells'].index(block) +1\n",
    "    #idxs.append(idx)\n",
    "    #log = []\n",
    "    #fpaths = []\n",
    "    for line in block['source']:\n",
    "        pattern = re.search(r\"'.*'\", line)\n",
    "        if pattern:\n",
    "            path = line[re.search(r\"'.*'\", line).start()+1:re.search(r\"'.*'\", line).end()-1]   \n",
    "            print(path)\n",
    "            if os.path.isfile(path) or os.path.isfile(path+'.pth') or os.path.isfile('models/'+path+'.pth'):\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #log = \n",
    "    log_block = {'cell_type': 'code', \n",
    "                   'execution_count': 0, \n",
    "                   'metadata': {}, \n",
    "                   'outputs': [], \n",
    "                   'source':log}\n",
    "    # insert a block that logs all filepaths at the end of notebook\n",
    "    notebook['cells'].insert(-1, log_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook['cells'][idxs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp1-example.ipynb', 'w') as fout:\n",
    "    json.dump(notebook, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
